{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_hfsjKPO2Y4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCS6O-yoO2Y6"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "#dataset taken from https://www.kaggle.com/yashsawarn/wifi-stretgth-for-rooms\n",
        "\n",
        "def read_dataset(csv_name = 'wifi_localization.txt'):\n",
        "    \"\"\"\n",
        "    Reads a csv dataset\n",
        "    returns it as a pytorch tensor\n",
        "    \"\"\"\n",
        "    data_frame = pandas.read_table(csv_name, delim_whitespace=True, names=('A', 'B', 'C', 'D','E', 'F', 'G', 'ROOM'),\n",
        "                       dtype={'A': np.int64, 'B': np.float64, 'C': np.float64, 'D': np.float64,'E': np.float64,'F': np.float64,'G': np.float64,'ROOM': np.float64})\n",
        "\n",
        "    targets_torch = torch.tensor(data_frame['ROOM'].values)\n",
        "    dataset_torch = torch.tensor(data_frame.values)\n",
        "\n",
        "    return dataset_torch\n",
        "dataset_torch = read_dataset()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9IbyV-lO2Y6",
        "outputId": "1c7b3a38-b2c9-486c-9263-2be018500274"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-64., -56., -61.,  ..., -82., -81.,   1.],\n",
            "        [-68., -57., -61.,  ..., -85., -85.,   1.],\n",
            "        [-63., -60., -60.,  ..., -85., -84.,   1.],\n",
            "        ...,\n",
            "        [-62., -59., -46.,  ..., -87., -88.,   4.],\n",
            "        [-62., -58., -52.,  ..., -90., -85.,   4.],\n",
            "        [-59., -50., -45.,  ..., -88., -87.,   4.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "print(dataset_torch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g3i5R8VvO2Y7"
      },
      "outputs": [],
      "source": [
        "class Node_CART:\n",
        "    def __init__(self, num_classes = 4, ref_CART = None, current_depth = 0):\n",
        "        \"\"\"\n",
        "        Create the node attributes\n",
        "        param num_classes: K number of classes to classify\n",
        "        param ref_cart: reference to the tree containing the node\n",
        "        param current_depth: current depth of the node in the tree\n",
        "        \"\"\"\n",
        "        self.ref_CART = ref_CART\n",
        "        self.threshold_value = 0\n",
        "        self.feature_num = 0\n",
        "        self.node_right = None\n",
        "        self.node_left = None\n",
        "        self.data_torch_partition = None\n",
        "        self.gini = 0\n",
        "        self.dominant_class = None\n",
        "        self.accuracy_dominant_class = None\n",
        "        self.num_classes = num_classes\n",
        "        self.current_depth = current_depth\n",
        "\n",
        "    def to_xml(self, current_str = \"\"):\n",
        "        \"\"\"\n",
        "        Recursive function to write the node content to an xml formatted string\n",
        "        param current_str : the xml content so far in the whole tree\n",
        "        return the string with the node content\n",
        "        \"\"\"\n",
        "        str_node = \"<node><thresh>\" + str(self.threshold_value) + \"</thresh>\" + \"<feature>\" + str(self.feature_num) + \"</feature><depth>\" + str(self.current_depth)+ \"</depth>\"\n",
        "        str_node += \"<gini>\" + str(self.gini) + \"</gini>\"\n",
        "        if(self.node_right != None):\n",
        "            str_left = self.node_right.to_xml(current_str)\n",
        "            str_node += str_left\n",
        "        if(self.node_left != None):\n",
        "            str_right = self.node_left.to_xml(current_str)\n",
        "            str_node += str_right\n",
        "\n",
        "        if(self.is_leaf()):\n",
        "            str_node += \"<dominant_class>\" + str(self.dominant_class) + \"</dominant_class><acc_dominant_class>\"  + str(self.accuracy_dominant_class) + \"</acc_dominant_class>\"\n",
        "        str_node += \"</node>\"\n",
        "        return str_node\n",
        "\n",
        "    def is_leaf(self):\n",
        "        \"\"\"\n",
        "        Checks whether the node is a leaf\n",
        "        \"\"\"\n",
        "        return (self.node_left == None and self.node_right == None)\n",
        "\n",
        "    def create_with_children(self, data_torch, current_depth, min_gini = 0.000001):\n",
        "        \"\"\"\n",
        "        Creates a node by selecting the best feature and threshold, and if needed, creating its children\n",
        "        param data_torch: dataset with the current partition to deal with in the node\n",
        "        param current_depth: depth counter for the node\n",
        "        param min_gini: hyperparmeter selected by the user defining the minimum tolerated gini coefficient for a  node\n",
        "        return the list of selected features so far\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        return list_selected_features\n",
        "\n",
        "\n",
        "def select_best_feature_and_thresh(data_torch, num_classes=2):\n",
        "    \"\"\"\n",
        "    Selecciona el atributo y el umbral que minimizan el Gini ponderado.\n",
        "\n",
        "    Parámetros\n",
        "    ----------\n",
        "    data_torch : torch.Tensor\n",
        "        Tensor con datos donde la última columna es la etiqueta de clase.\n",
        "    num_classes : int, por defecto 2\n",
        "        Número de clases posibles.\n",
        "\n",
        "    Retorna\n",
        "    -------\n",
        "    best_feature : int\n",
        "        Índice de la característica que produce la menor impureza de Gini.\n",
        "    best_thresh : float\n",
        "        Valor umbral para dividir en esa característica.\n",
        "    best_gini : float\n",
        "        Impureza de Gini ponderada para esta división óptima.\n",
        "\n",
        "    Detalles de implementación\n",
        "    --------------------------\n",
        "    - Se itera solo sobre atributos y umbrales posibles.\n",
        "    - Se usan máscaras booleanas para dividir los datos:\n",
        "        left_mask = data[:, f] <= t\n",
        "        right_mask = ~left_mask\n",
        "    - Gini ponderado: (nL/n)*GL + (nR/n)*GR\n",
        "    - Se busca el mínimo sobre todas las divisiones posibles.\n",
        "    \"\"\"\n",
        "    n_samples, n_features_plus_label = data_torch.shape\n",
        "    n_features = n_features_plus_label - 1\n",
        "\n",
        "    best_feature, best_thresh, best_gini = None, None, float('inf')\n",
        "\n",
        "    # Iterar sobre cada atributo (feature)\n",
        "    for f in range(n_features):\n",
        "        # Valores únicos como candidatos de umbral\n",
        "        values = torch.unique(data_torch[:, f])\n",
        "\n",
        "        for thresh in values:\n",
        "            # Crear máscaras booleanas sin bucles\n",
        "            left_mask = data_torch[:, f] <= thresh\n",
        "            right_mask = ~left_mask\n",
        "\n",
        "            left_data = data_torch[left_mask]\n",
        "            right_data = data_torch[right_mask]\n",
        "\n",
        "            # Calcular gini de cada lado\n",
        "            gini_left = calculate_gini(left_data, num_classes)\n",
        "            gini_right = calculate_gini(right_data, num_classes)\n",
        "\n",
        "            # Calcular gini ponderado\n",
        "            n_left, n_right = left_data.shape[0], right_data.shape[0]\n",
        "            gini_split = (n_left * gini_left + n_right * gini_right) / n_samples\n",
        "\n",
        "            # Verificar si es la mejor división\n",
        "            if gini_split < best_gini:\n",
        "                best_gini = gini_split\n",
        "                best_feature = f\n",
        "                best_thresh = thresh.item()\n",
        "\n",
        "    return best_feature, best_thresh, best_gini\n",
        "\n",
        "\n",
        "    def calculate_gini(data_partition_torch, num_classes=2):\n",
        "      \"\"\"\n",
        "      Calcula el coeficiente de Gini para una partición de datos.\n",
        "\n",
        "      Parámetros\n",
        "      ----------\n",
        "      data_partition_torch : torch.Tensor\n",
        "          Tensor donde la última columna contiene las etiquetas de clase.\n",
        "      num_classes : int, por defecto 2\n",
        "          Número de clases posibles en el conjunto de datos.\n",
        "\n",
        "      Retorna\n",
        "      -------\n",
        "      gini : float\n",
        "          Impureza de Gini para la partición dada.\n",
        "\n",
        "      Detalles de implementación\n",
        "      --------------------------\n",
        "      - torch.bincount: cuenta el número de ocurrencias de cada etiqueta.\n",
        "      - torch.sum: suma los elementos de un tensor.\n",
        "      - Se evita el uso de bucles de Python: todo está vectorizado.\n",
        "      - Fórmula: G = 1 - Σ(p_k^2), donde p_k = frecuencia relativa de la clase k.\n",
        "      \"\"\"\n",
        "      if data_partition_torch.numel() == 0:\n",
        "          # Si la partición está vacía, por definición no hay impureza.\n",
        "          return 0.0\n",
        "\n",
        "      # Extraer etiquetas (suponemos que la última columna son las etiquetas)\n",
        "      labels = data_partition_torch[:, -1].long()\n",
        "\n",
        "      # Contar ocurrencias por clase (minlength garantiza tamaño fijo del vector)\n",
        "      counts = torch.bincount(labels, minlength=num_classes)\n",
        "\n",
        "      # Convertir a probabilidades dividiendo entre el total\n",
        "      probs = counts.float() / counts.sum()\n",
        "\n",
        "      # Calcular Gini: 1 - suma de cuadrados de probabilidades\n",
        "      gini = 1.0 - torch.sum(probs ** 2)\n",
        "      return gini.item()\n",
        "\n",
        "    def calculate_gini(self, data_partition_torch, num_classes = 4):\n",
        "        \"\"\"\n",
        "        Calculates the gini coefficient for a given partition with the given number of classes\n",
        "        param data_partition_torch: current dataset partition as a tensor\n",
        "        param num_classes: K number of classes to discriminate from\n",
        "        returns the calculated gini coefficient\n",
        "        \"\"\"\n",
        "        def gini_for_subset(subset):\n",
        "            if subset.shape[0] == 0:\n",
        "                return 0.0\n",
        "            gini = 1.0\n",
        "            total = subset.shape[0]\n",
        "            for cls in range(num_classes):\n",
        "                count = torch.sum(subset[:, -1] == cls).item()\n",
        "                prob = count / total\n",
        "                gini -= prob ** 2\n",
        "            return gini\n",
        "        gini = gini_for_subset(data_partition_torch)\n",
        "        return gini\n",
        "\n",
        "\n",
        "\n",
        "    def evaluate_node(self, input_torch):\n",
        "        \"\"\"\n",
        "        Evaluates an input observation within the node.\n",
        "        If is not a leaf node, send it to the corresponding node\n",
        "        return predicted label\n",
        "        \"\"\"\n",
        "        feature_val_input = input_torch[self.feature_num]\n",
        "        if(self.is_leaf()):\n",
        "            return self.dominant_class\n",
        "        else:\n",
        "            if(feature_val_input < self.threshold_value):\n",
        "                return self.node_left.evaluate_node(input_torch)\n",
        "            else:\n",
        "                return self.node_right.evaluate_node(input_torch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b89NWwPSO2Y8",
        "outputId": "93b42d97-0158-4c5e-c699-a9ba06054f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset_example \n",
            " tensor([[ 3.0000, 22.0000,  7.2000,  0.0000],\n",
            "        [ 1.0000, 38.0000, 71.3000,  0.0000],\n",
            "        [ 3.0000, 26.0000,  7.9000,  1.0000],\n",
            "        [ 1.0000, 35.0000, 53.1000,  0.0000]])\n"
          ]
        }
      ],
      "source": [
        "dataset_example = torch.tensor([[3, 22.0, 7.2, 0], [1, 38, 71.3, 0], [3, 26, 7.9, 1], [1, 35, 53.1, 0]])\n",
        "print(\"dataset_example \\n\", dataset_example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8Fo0k1uO2Y-",
        "outputId": "165b4d85-6e4a-421d-be1a-33dd438aa4d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root node \n",
            "  tensor([[ 3.0000, 22.0000,  7.2000,  0.0000],\n",
            "        [ 1.0000, 38.0000, 71.3000,  0.0000],\n",
            "        [ 3.0000, 26.0000,  7.9000,  1.0000],\n",
            "        [ 1.0000, 35.0000, 53.1000,  0.0000]])\n",
            "xml_root_node \n",
            " <node><thresh>0</thresh><feature>0</feature><depth>0</depth><gini>0</gini><dominant_class>None</dominant_class><acc_dominant_class>None</acc_dominant_class></node>\n"
          ]
        }
      ],
      "source": [
        "root_node = Node_CART()\n",
        "root_node.data_torch_partition = dataset_example\n",
        "\n",
        "print(\"root node \\n \", root_node.data_torch_partition)\n",
        "xml_root_node = root_node.to_xml()\n",
        "\n",
        "print(\"xml_root_node \\n\", xml_root_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilEWeYiIO2Y-",
        "outputId": "2bed79bb-7b5d-426a-a403-727337271e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset_partition_left \n",
            " tensor([[ 1.0000, 38.0000, 71.3000,  0.0000],\n",
            "        [ 1.0000, 35.0000, 53.1000,  0.0000]])\n",
            "dataset_partition_right \n",
            " tensor([[ 3.0000, 22.0000,  7.2000,  0.0000],\n",
            "        [ 3.0000, 26.0000,  7.9000,  1.0000]])\n"
          ]
        }
      ],
      "source": [
        "root_node.threshold_value = 3\n",
        "root_node.feature_num = 0\n",
        "\n",
        "#indices of left and right partitions\n",
        "left_idxs = dataset_example[:, root_node.feature_num] < root_node.threshold_value\n",
        "right_idxs = dataset_example[:, root_node.feature_num] >= root_node.threshold_value\n",
        "#data partitions\n",
        "dataset_partition_left = dataset_example[left_idxs]\n",
        "dataset_partition_right = dataset_example[right_idxs]\n",
        "\n",
        "print(\"dataset_partition_left \\n\", dataset_partition_left)\n",
        "print(\"dataset_partition_right \\n\", dataset_partition_right)\n",
        "#create left child\n",
        "left_child = Node_CART(current_depth = 1)\n",
        "left_child.data_torch_partition = dataset_partition_left\n",
        "root_node.node_left = left_child\n",
        "#create right child\n",
        "right_child = Node_CART(current_depth = 1)\n",
        "right_child.data_torch_partition = dataset_partition_right\n",
        "root_node.node_right = right_child\n",
        "#write xml example\n",
        "root_node.ref_CART = root_node\n",
        "xml_string = root_node.to_xml()\n",
        "\n",
        "#print(xml_string)\n",
        "file = open(\"example1.xml\", \"a\")\n",
        "file.write(xml_string)\n",
        "file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA9GDNpDO2Y_",
        "outputId": "bc997d43-8d66-4e28-818a-93879464a4a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<node><thresh>3</thresh><feature>0</feature><depth>0</depth><gini>0</gini><node><thresh>0</thresh><feature>0</feature><depth>1</depth><gini>0</gini><dominant_class>None</dominant_class><acc_dominant_class>None</acc_dominant_class></node><node><thresh>0</thresh><feature>0</feature><depth>1</depth><gini>0</gini><dominant_class>None</dominant_class><acc_dominant_class>None</acc_dominant_class></node></node>\n"
          ]
        }
      ],
      "source": [
        "print(xml_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdD4lGFZO2ZC",
        "outputId": "62be5af2-f5fa-4777-8e2f-85d76c8e0cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gini_left:  0.4444444444444444 gini_right:  0.0 gini_total:  0.3333333333333333\n",
            "gini_total  0.3333333333333333\n"
          ]
        }
      ],
      "source": [
        "def calculate_gini(node_left, node_right):\n",
        "  size_left = node_left.data_torch_partition.shape[0]\n",
        "  size_right = node_right.data_torch_partition.shape[0]\n",
        "  size_total = size_left + size_right\n",
        "  gini_left = 1 - (((node_left.data_torch_partition[:, 3] == 0).sum().item() / size_left)**2 + ((node_left.data_torch_partition[:, 3] == 1).sum().item()/size_left)**2)\n",
        "  gini_right = 1 - (((node_right.data_torch_partition[:, 3] == 0).sum().item() / size_right)**2 + ((node_right.data_torch_partition[:, 3] == 1).sum().item()/size_right)**2)\n",
        "  gini_total = (size_left / size_total * gini_left) + (size_right / size_total * gini_right)\n",
        "  print(\"gini_left: \", gini_left, \"gini_right: \", gini_right, \"gini_total: \", gini_total)\n",
        "  return gini_total\n",
        "gini_total = calculate_gini(left_child, right_child)\n",
        "print(\"gini_total \", gini_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6scdd5CoO2ZE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSQHnsCCO2ZE"
      },
      "outputs": [],
      "source": [
        "# Prueba unitaria 1: Gini para un solo grupo homogéneo (impureza debe ser 0)\n",
        "def test_gini_homogeneous():\n",
        "    node = Node_CART(num_classes=2)\n",
        "    # Todos los elementos son de la clase 0\n",
        "    data = torch.tensor([[1, 2, 0], [2, 3, 0], [3, 4, 0]], dtype=torch.float32)\n",
        "    gini = node.calculate_gini(data, num_classes=2)\n",
        "    print('Test 1 - Gini homogéneo:', gini)\n",
        "    assert abs(gini - 0.0) < 1e-6, f\"Esperado 0.0, obtenido {gini}\"\n",
        "\n",
        "# Prueba unitaria 2: Gini para dos clases balanceadas (impureza máxima)\n",
        "def test_gini_balanced():\n",
        "    node = Node_CART(num_classes=2)\n",
        "    # Mitad clase 0, mitad clase 1\n",
        "    data = torch.tensor([[1, 2, 0], [2, 3, 1], [3, 4, 0], [4, 5, 1]], dtype=torch.float32)\n",
        "    gini = node.calculate_gini(data, num_classes=2)\n",
        "    print('Test 2 - Gini balanceado:', gini)\n",
        "    assert abs(gini - 0.5) < 1e-6, f\"Esperado 0.5, obtenido {gini}\"\n",
        "\n",
        "# Ejecutar pruebas\n",
        "if __name__ == \"__main__\":\n",
        "    test_gini_homogeneous()\n",
        "    test_gini_balanced()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}