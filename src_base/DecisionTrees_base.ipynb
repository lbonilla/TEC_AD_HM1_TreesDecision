{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F_hfsjKPO2Y4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uCS6O-yoO2Y6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "035dd94b-502f-4ddd-f8f7-9e9d0b726674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2369501803.py:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_table is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  data_frame = pandas.read_table(csv_name, delim_whitespace=True, names=('A', 'B', 'C', 'D','E', 'F', 'G', 'ROOM'),\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'wifi_localization.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2369501803.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset_torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdataset_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2369501803.py\u001b[0m in \u001b[0;36mread_dataset\u001b[0;34m(csv_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreturns\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpytorch\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m     data_frame = pandas.read_table(csv_name, delim_whitespace=True, names=('A', 'B', 'C', 'D','E', 'F', 'G', 'ROOM'),\n\u001b[0m\u001b[1;32m     10\u001b[0m                        dtype={'A': np.int64, 'B': np.float64, 'C': np.float64, 'D': np.float64,'E': np.float64,'F': np.float64,'G': np.float64,'ROOM': np.float64})\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wifi_localization.txt'"
          ]
        }
      ],
      "source": [
        "import pandas\n",
        "#dataset taken from https://www.kaggle.com/yashsawarn/wifi-stretgth-for-rooms\n",
        "\n",
        "def read_dataset(csv_name = 'wifi_localization.txt'):\n",
        "    \"\"\"\n",
        "    Reads a csv dataset\n",
        "    returns it as a pytorch tensor\n",
        "    \"\"\"\n",
        "    data_frame = pandas.read_table(csv_name, delim_whitespace=True, names=('A', 'B', 'C', 'D','E', 'F', 'G', 'ROOM'),\n",
        "                       dtype={'A': np.int64, 'B': np.float64, 'C': np.float64, 'D': np.float64,'E': np.float64,'F': np.float64,'G': np.float64,'ROOM': np.float64})\n",
        "\n",
        "    targets_torch = torch.tensor(data_frame['ROOM'].values)\n",
        "    dataset_torch = torch.tensor(data_frame.values)\n",
        "\n",
        "    return dataset_torch\n",
        "dataset_torch = read_dataset()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l9IbyV-lO2Y6",
        "outputId": "d7448b20-ed96-4978-c0ad-c36677f8abab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataset_torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3228081930.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_torch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset_torch' is not defined"
          ]
        }
      ],
      "source": [
        "print(dataset_torch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b89NWwPSO2Y8",
        "outputId": "11d6c0c5-8ebc-4107-c65d-0e42f4db5e2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset_example \n",
            " tensor([[ 3.0000, 22.0000,  7.2000,  1.0000],\n",
            "        [ 1.0000, 38.0000, 71.3000,  1.0000],\n",
            "        [ 3.0000, 26.0000,  7.9000,  1.0000],\n",
            "        [ 1.0000, 35.0000, 53.1000,  1.0000]])\n"
          ]
        }
      ],
      "source": [
        "dataset_example = torch.tensor([[3, 22.0, 7.2, 1], [1, 38, 71.3, 1], [3, 26, 7.9, 1], [1, 35, 53.1, 1]])\n",
        "print(\"dataset_example \\n\", dataset_example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N8Fo0k1uO2Y-",
        "outputId": "971c52d7-a7d1-4ffe-87ea-5005261e0548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Node_CART' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-997056701.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroot_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode_CART\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_torch_partition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"root node \\n \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_torch_partition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxml_root_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Node_CART' is not defined"
          ]
        }
      ],
      "source": [
        "root_node = Node_CART()\n",
        "root_node.data_torch_partition = dataset_example\n",
        "\n",
        "print(\"root node \\n \", root_node.data_torch_partition)\n",
        "xml_root_node = root_node.to_xml()\n",
        "\n",
        "print(\"xml_root_node \\n\", xml_root_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ilEWeYiIO2Y-",
        "outputId": "7ef6e8b5-23c0-4242-fb9a-af8bd6fbceb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'root_node' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-248663239.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#indices of left and right partitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mleft_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_example\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'root_node' is not defined"
          ]
        }
      ],
      "source": [
        "root_node.threshold_value = 3\n",
        "root_node.feature_num = 0\n",
        "\n",
        "#indices of left and right partitions\n",
        "left_idxs = dataset_example[:, root_node.feature_num] < root_node.threshold_value\n",
        "right_idxs = dataset_example[:, root_node.feature_num] >= root_node.threshold_value\n",
        "#data partitions\n",
        "dataset_partition_left = dataset_example[left_idxs]\n",
        "dataset_partition_right = dataset_example[right_idxs]\n",
        "\n",
        "print(\"dataset_partition_left \\n\", dataset_partition_left)\n",
        "print(\"dataset_partition_right \\n\", dataset_partition_right)\n",
        "#create left child\n",
        "left_child = Node_CART(current_depth = 1)\n",
        "left_child.data_torch_partition = dataset_partition_left\n",
        "root_node.node_left = left_child\n",
        "#create right child\n",
        "right_child = Node_CART(current_depth = 1)\n",
        "right_child.data_torch_partition = dataset_partition_right\n",
        "root_node.node_right = right_child\n",
        "#write xml example\n",
        "root_node.ref_CART = root_node\n",
        "xml_string = root_node.to_xml()\n",
        "\n",
        "#print(xml_string)\n",
        "file = open(\"example1.xml\", \"a\")\n",
        "file.write(xml_string)\n",
        "file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nA9GDNpDO2Y_",
        "outputId": "c852dcb9-ed8b-4732-ba23-631e3291cd06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<node><thresh>3</thresh><feature>0</feature><depth>0</depth><gini>0</gini><node><thresh>0</thresh><feature>0</feature><depth>1</depth><gini>0</gini><dominant_class>None</dominant_class><acc_dominant_class>None</acc_dominant_class></node><node><thresh>0</thresh><feature>0</feature><depth>1</depth><gini>0</gini><dominant_class>None</dominant_class><acc_dominant_class>None</acc_dominant_class></node></node>\n"
          ]
        }
      ],
      "source": [
        "print(xml_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g3i5R8VvO2Y7"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Node_CART:\n",
        "    def __init__(self, num_classes=4, ref_CART=None, current_depth=0):\n",
        "        self.ref_CART = ref_CART\n",
        "        self.threshold_value = 0\n",
        "        self.feature_num = 0\n",
        "        self.node_right = None\n",
        "        self.node_left = None\n",
        "        self.data_torch_partition = None\n",
        "        self.gini = 0\n",
        "        self.dominant_class = None\n",
        "        self.accuracy_dominant_class = None\n",
        "        self.num_classes = num_classes\n",
        "        self.current_depth = current_depth\n",
        "        self.max_depth = None  # Optional: set externally if needed\n",
        "\n",
        "    def to_xml(self, current_str=\"\"):\n",
        "        str_node = \"<node><thresh>\" + str(self.threshold_value) + \"</thresh>\" + \"<feature>\" + str(self.feature_num) + \"</feature><depth>\" + str(self.current_depth)+ \"</depth>\"\n",
        "        str_node += \"<gini>\" + str(self.gini) + \"</gini>\"\n",
        "        if self.node_right is not None:\n",
        "            str_node += self.node_right.to_xml(current_str)\n",
        "        if self.node_left is not None:\n",
        "            str_node += self.node_left.to_xml(current_str)\n",
        "        if self.is_leaf():\n",
        "            str_node += \"<dominant_class>\" + str(self.dominant_class) + \"</dominant_class><acc_dominant_class>\"  + str(self.accuracy_dominant_class) + \"</acc_dominant_class>\"\n",
        "        str_node += \"</node>\"\n",
        "        return str_node\n",
        "\n",
        "    def is_leaf(self):\n",
        "        return (self.node_left is None and self.node_right is None)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_gini(data_partition_torch, num_classes=2):\n",
        "        if data_partition_torch.numel() == 0:\n",
        "            return 0.0\n",
        "        labels = data_partition_torch[:, -1].long()\n",
        "        # Cuenta cuántos ejemplos hay de cada clase\n",
        "        counts = torch.bincount(labels, minlength=num_classes)\n",
        "        probs = counts.float() / counts.sum()\n",
        "        gini = 1.0 - torch.sum(probs ** 2)\n",
        "        return gini.item()\n",
        "\n",
        "    def create_with_children(self, data_torch, current_depth, min_gini=0.000001):\n",
        "        labels = data_torch[:, -1].long()\n",
        "        counts = torch.bincount(labels, minlength=self.num_classes).float()\n",
        "        self.dominant_class = torch.argmax(counts).item()\n",
        "\n",
        "        # If pure node, make leaf\n",
        "        if (counts > 0).sum() == 1:\n",
        "            return self\n",
        "\n",
        "        # If max depth reached\n",
        "        if self.max_depth is not None and current_depth >= self.max_depth:\n",
        "            return self\n",
        "\n",
        "        # Select best split\n",
        "        feature, thresh, gini = self.select_best_feature_and_thresh(data_torch, self.num_classes)\n",
        "\n",
        "        # If no good split, make leaf\n",
        "        if feature is None or gini < min_gini:\n",
        "            return self\n",
        "\n",
        "        self.feature_num = feature\n",
        "        self.threshold_value = thresh\n",
        "        self.gini = gini\n",
        "\n",
        "        # Partition data\n",
        "        left_mask = data_torch[:, feature] <= thresh\n",
        "        right_mask = ~left_mask\n",
        "\n",
        "        left_partition = data_torch[left_mask]\n",
        "        right_partition = data_torch[right_mask]\n",
        "\n",
        "        # Create child nodes\n",
        "        self.node_left = Node_CART(num_classes=self.num_classes, current_depth=current_depth + 1)\n",
        "        self.node_right = Node_CART(num_classes=self.num_classes, current_depth=current_depth + 1)\n",
        "        self.node_left.max_depth = self.max_depth\n",
        "        self.node_right.max_depth = self.max_depth\n",
        "\n",
        "        self.node_left.create_with_children(left_partition, current_depth + 1, min_gini)\n",
        "        self.node_right.create_with_children(right_partition, current_depth + 1, min_gini)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def select_best_feature_and_thresh(self, data_torch, num_classes=2):\n",
        "        n_samples, n_features = data_torch.shape[0], data_torch.shape[1] - 1\n",
        "        best_gini = float('inf')\n",
        "        best_feature = None\n",
        "        best_thresh = None\n",
        "\n",
        "        for feature_idx in range(n_features):\n",
        "            feature_values = data_torch[:, feature_idx]\n",
        "            thresholds = torch.unique(feature_values)\n",
        "\n",
        "            for thresh in thresholds:\n",
        "                left_mask = feature_values <= thresh\n",
        "                right_mask = ~left_mask\n",
        "\n",
        "                left_partition = data_torch[left_mask]\n",
        "                right_partition = data_torch[right_mask]\n",
        "\n",
        "                gini_left = self.calculate_gini(left_partition, num_classes)\n",
        "                gini_right = self.calculate_gini(right_partition, num_classes)\n",
        "\n",
        "                weighted_gini = (left_partition.size(0) * gini_left +\n",
        "                                 right_partition.size(0) * gini_right) / n_samples\n",
        "\n",
        "                if weighted_gini < best_gini:\n",
        "                    best_gini = weighted_gini\n",
        "                    best_feature = feature_idx\n",
        "                    best_thresh = thresh.item()\n",
        "\n",
        "        return best_feature, best_thresh, best_gini\n",
        "\n",
        "    def evaluate_node(self, input_torch):\n",
        "        feature_val_input = input_torch[self.feature_num]\n",
        "        if self.is_leaf():\n",
        "            return self.dominant_class\n",
        "        else:\n",
        "            if feature_val_input < self.threshold_value:\n",
        "                return self.node_left.evaluate_node(input_torch)\n",
        "            else:\n",
        "                return self.node_right.evaluate_node(input_torch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kdD4lGFZO2ZC",
        "outputId": "f0fbcb43-a591-4349-f9ab-dd4b944739ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gini_left:  0.0 gini_right:  0.5 gini_total:  0.25\n",
            "gini_total  0.25\n"
          ]
        }
      ],
      "source": [
        "def calculate_gini(node_left, node_right):\n",
        "  size_left = node_left.data_torch_partition.shape[0]\n",
        "  size_right = node_right.data_torch_partition.shape[0]\n",
        "  size_total = size_left + size_right\n",
        "  gini_left = 1 - (((node_left.data_torch_partition[:, 3] == 0).sum().item() / size_left)**2 + ((node_left.data_torch_partition[:, 3] == 1).sum().item()/size_left)**2)\n",
        "  gini_right = 1 - (((node_right.data_torch_partition[:, 3] == 0).sum().item() / size_right)**2 + ((node_right.data_torch_partition[:, 3] == 1).sum().item()/size_right)**2)\n",
        "  gini_total = (size_left / size_total * gini_left) + (size_right / size_total * gini_right)\n",
        "  print(\"gini_left: \", gini_left, \"gini_right: \", gini_right, \"gini_total: \", gini_total)\n",
        "  return gini_total\n",
        "gini_total = calculate_gini(left_child, right_child)\n",
        "print(\"gini_total \", gini_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SSQHnsCCO2ZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb3390d-0534-4254-9f04-a8645e3527e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1 - Gini homogéneo: 0.0\n",
            "Test 2 - Gini balanceado: 0.5\n"
          ]
        }
      ],
      "source": [
        "# Prueba unitaria 1: Gini para un solo grupo homogéneo (impureza debe ser 0)\n",
        "def test_gini_homogeneous():\n",
        "    node = Node_CART(num_classes=2)\n",
        "    # Todos los elementos son de la clase 0\n",
        "    data = torch.tensor([[1, 2, 0], [2, 3, 0], [3, 4, 0]], dtype=torch.float32)\n",
        "    gini = node.calculate_gini(data, num_classes=2)\n",
        "    print('Test 1 - Gini homogéneo:', gini)\n",
        "    assert abs(gini - 0.0) < 1e-6, f\"Esperado 0.0, obtenido {gini}\"\n",
        "\n",
        "# Prueba unitaria 2: Gini para dos clases balanceadas (impureza máxima)\n",
        "def test_gini_balanced():\n",
        "    node = Node_CART(num_classes=2)\n",
        "    # Mitad clase 0, mitad clase 1\n",
        "    data = torch.tensor([[1, 2, 0], [2, 3, 1], [3, 4, 0], [4, 5, 1]], dtype=torch.float32)\n",
        "    gini = node.calculate_gini(data, num_classes=2)\n",
        "    print('Test 2 - Gini balanceado:', gini)\n",
        "    assert abs(gini - 0.5) < 1e-6, f\"Esperado 0.5, obtenido {gini}\"\n",
        "\n",
        "# Ejecutar pruebas\n",
        "if __name__ == \"__main__\":\n",
        "    test_gini_homogeneous()\n",
        "    test_gini_balanced()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6scdd5CoO2ZE"
      },
      "outputs": [],
      "source": [
        "newNode = Node_CART(num_classes=2)\n",
        "newNode.create_with_children(dataset_example, 0)\n",
        "xml_string =newNode.to_xml()\n",
        "\n",
        "#print(xml_string)\n",
        "file = open(\"example1.xml\", \"a\")\n",
        "file.write(xml_string)\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xml_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVfxRp7jXA5B",
        "outputId": "036f7462-9a35-4915-ff38-b09c57ed1eec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<node><thresh>0</thresh><feature>0</feature><depth>0</depth><gini>0</gini><dominant_class>1</dominant_class><acc_dominant_class>None</acc_dominant_class></node>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit Tests"
      ],
      "metadata": {
        "id": "69xp2326yC7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def test_select_best_feature_and_thresh():\n",
        "    # El feature 0 separa perfectamente las clases con threshold 2\n",
        "    # [feature0, feature1, clase]\n",
        "    data = torch.tensor([\n",
        "        [1.0, 10.0, 0],\n",
        "        [2.0, 20.0, 0],\n",
        "        [3.0, 30.0, 1],\n",
        "        [4.0, 40.0, 1]\n",
        "    ])\n",
        "\n",
        "    node = Node_CART(num_classes=2)\n",
        "    best_feature, best_thresh, best_gini = node.select_best_feature_and_thresh(data, num_classes=2)\n",
        "\n",
        "    print(\"Mejor feature:\", best_feature)\n",
        "    print(\"Mejor threshold:\", best_thresh)\n",
        "    print(\"Mejor gini:\", best_gini)\n",
        "\n",
        "    # Esperamos que el mejor feature sea 0 y el mejor threshold sea 2.0 o 3.0 (ambos separan perfectamente)\n",
        "    assert best_feature == 0, \"El mejor feature debería ser la columna 0\"\n",
        "    assert best_thresh == 2.0 , \"El mejor threshold debería ser 2.0 o 3.0\"\n",
        "    assert best_gini == 0.0, \"El gini debería ser 0 para una separación perfecta\"\n",
        "\n",
        "\n",
        "\n",
        "def test_select_best_feature_and_thresh_feature2():\n",
        "    # Dataset: solo la columna 2 permite separación perfecta con threshold 12.5\n",
        "    # [feature0, feature1, feature2, clase]\n",
        "    data = torch.tensor([\n",
        "        [0.0, 1.0, 10.0, 1],\n",
        "        [0.0, 1.0, 11.0, 1],\n",
        "        [0.0, 1.0, 12.0, 1],\n",
        "        [0.0, 1.0, 13.0, 0],\n",
        "        [0.0, 1.0, 14.0, 0],\n",
        "        [0.0, 1.0, 15.0, 0],\n",
        "        [0.0, 1.0, 16.0, 0],\n",
        "        [0.0, 1.0, 17.0, 0],\n",
        "    ])\n",
        "\n",
        "    node = Node_CART(num_classes=2)\n",
        "    best_feature, best_thresh, best_gini = node.select_best_feature_and_thresh(data, num_classes=2)\n",
        "\n",
        "    print(\"Mejor feature:\", best_feature)\n",
        "    print(\"Mejor threshold:\", best_thresh)\n",
        "    print(\"Mejor gini:\", best_gini)\n",
        "\n",
        "    # Esperamos que el mejor feature sea 2 (columna 2) y threshold 12.0 o 13.0\n",
        "    assert best_feature == 2, \"El mejor feature debería ser la columna 2\"\n",
        "\n",
        "    assert best_thresh == 12.0 , \"El mejor threshold debería separar clases 0 y 1\"\n",
        "    assert best_gini == 0.0, \"El gini debería ser 0 para una separación perfecta\"\n",
        "\n",
        "print(\" *** Unit test de select_best_feature_and_thresh \")\n",
        "print(\"Test #1 de la función select_best_feature_and_thresh. El feature 0 separa perfectamente las clases con threshold 2.5\")\n",
        "test_select_best_feature_and_thresh()\n",
        "\n",
        "print(\"_____________________________________________________\")\n",
        "\n",
        "print(\"Test #1 de la función select_best_feature_and_thresh. El feature 0 separa perfectamente las clases con threshold 2.5\")\n",
        "test_select_best_feature_and_thresh_feature2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl9Z-gNkyGsP",
        "outputId": "aafcf89d-7edf-4d00-901f-465f25fb311f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " *** Unit test de select_best_feature_and_thresh \n",
            "Test #1 de la función select_best_feature_and_thresh. El feature 0 separa perfectamente las clases con threshold 2.5\n",
            "Mejor feature: 0\n",
            "Mejor threshold: 2.0\n",
            "Mejor gini: 0.0\n",
            "_____________________________________________________\n",
            "Test #1 de la función select_best_feature_and_thresh. El feature 0 separa perfectamente las clases con threshold 2.5\n",
            "Mejor feature: 2\n",
            "Mejor threshold: 12.0\n",
            "Mejor gini: 0.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}