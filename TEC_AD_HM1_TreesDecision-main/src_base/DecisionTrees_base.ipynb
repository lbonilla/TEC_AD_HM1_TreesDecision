{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F_hfsjKPO2Y4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uCS6O-yoO2Y6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "035dd94b-502f-4ddd-f8f7-9e9d0b726674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2369501803.py:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_table is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  data_frame = pandas.read_table(csv_name, delim_whitespace=True, names=('A', 'B', 'C', 'D','E', 'F', 'G', 'ROOM'),\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'wifi_localization.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2369501803.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset_torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdataset_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2369501803.py\u001b[0m in \u001b[0;36mread_dataset\u001b[0;34m(csv_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreturns\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpytorch\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m     data_frame = pandas.read_table(csv_name, delim_whitespace=True, names=('A', 'B', 'C', 'D','E', 'F', 'G', 'ROOM'),\n\u001b[0m\u001b[1;32m     10\u001b[0m                        dtype={'A': np.int64, 'B': np.float64, 'C': np.float64, 'D': np.float64,'E': np.float64,'F': np.float64,'G': np.float64,'ROOM': np.float64})\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wifi_localization.txt'"
          ]
        }
      ],
      "source": [
        "import pandas\n",
        "#dataset taken from https://www.kaggle.com/yashsawarn/wifi-stretgth-for-rooms\n",
        "\n",
        "def read_dataset(csv_name = 'wifi_localization.txt'):\n",
        "    \"\"\"\n",
        "    Reads a csv dataset\n",
        "    returns it as a pytorch tensor\n",
        "    \"\"\"\n",
        "    data_frame = pandas.read_table(csv_name, delim_whitespace=True, names=('A', 'B', 'C', 'D','E', 'F', 'G', 'ROOM'),\n",
        "                       dtype={'A': np.int64, 'B': np.float64, 'C': np.float64, 'D': np.float64,'E': np.float64,'F': np.float64,'G': np.float64,'ROOM': np.float64})\n",
        "\n",
        "    targets_torch = torch.tensor(data_frame['ROOM'].values)\n",
        "    dataset_torch = torch.tensor(data_frame.values)\n",
        "\n",
        "    return dataset_torch\n",
        "dataset_torch = read_dataset()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l9IbyV-lO2Y6",
        "outputId": "d7448b20-ed96-4978-c0ad-c36677f8abab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataset_torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3228081930.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_torch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset_torch' is not defined"
          ]
        }
      ],
      "source": [
        "print(dataset_torch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b89NWwPSO2Y8",
        "outputId": "11d6c0c5-8ebc-4107-c65d-0e42f4db5e2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset_example \n",
            " tensor([[ 3.0000, 22.0000,  7.2000,  1.0000],\n",
            "        [ 1.0000, 38.0000, 71.3000,  1.0000],\n",
            "        [ 3.0000, 26.0000,  7.9000,  1.0000],\n",
            "        [ 1.0000, 35.0000, 53.1000,  1.0000]])\n"
          ]
        }
      ],
      "source": [
        "dataset_example = torch.tensor([[3, 22.0, 7.2, 1], [1, 38, 71.3, 1], [3, 26, 7.9, 1], [1, 35, 53.1, 1]])\n",
        "print(\"dataset_example \\n\", dataset_example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N8Fo0k1uO2Y-",
        "outputId": "971c52d7-a7d1-4ffe-87ea-5005261e0548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Node_CART' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-997056701.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroot_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode_CART\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_torch_partition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"root node \\n \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_torch_partition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxml_root_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Node_CART' is not defined"
          ]
        }
      ],
      "source": [
        "root_node = Node_CART()\n",
        "root_node.data_torch_partition = dataset_example\n",
        "\n",
        "print(\"root node \\n \", root_node.data_torch_partition)\n",
        "xml_root_node = root_node.to_xml()\n",
        "\n",
        "print(\"xml_root_node \\n\", xml_root_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ilEWeYiIO2Y-",
        "outputId": "7ef6e8b5-23c0-4242-fb9a-af8bd6fbceb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'root_node' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-248663239.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#indices of left and right partitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mleft_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_example\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'root_node' is not defined"
          ]
        }
      ],
      "source": [
        "root_node.threshold_value = 3\n",
        "root_node.feature_num = 0\n",
        "\n",
        "#indices of left and right partitions\n",
        "left_idxs = dataset_example[:, root_node.feature_num] < root_node.threshold_value\n",
        "right_idxs = dataset_example[:, root_node.feature_num] >= root_node.threshold_value\n",
        "#data partitions\n",
        "dataset_partition_left = dataset_example[left_idxs]\n",
        "dataset_partition_right = dataset_example[right_idxs]\n",
        "\n",
        "print(\"dataset_partition_left \\n\", dataset_partition_left)\n",
        "print(\"dataset_partition_right \\n\", dataset_partition_right)\n",
        "#create left child\n",
        "left_child = Node_CART(current_depth = 1)\n",
        "left_child.data_torch_partition = dataset_partition_left\n",
        "root_node.node_left = left_child\n",
        "#create right child\n",
        "right_child = Node_CART(current_depth = 1)\n",
        "right_child.data_torch_partition = dataset_partition_right\n",
        "root_node.node_right = right_child\n",
        "#write xml example\n",
        "root_node.ref_CART = root_node\n",
        "xml_string = root_node.to_xml()\n",
        "\n",
        "#print(xml_string)\n",
        "file = open(\"example1.xml\", \"a\")\n",
        "file.write(xml_string)\n",
        "file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nA9GDNpDO2Y_",
        "outputId": "c852dcb9-ed8b-4732-ba23-631e3291cd06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<node><thresh>3</thresh><feature>0</feature><depth>0</depth><gini>0</gini><node><thresh>0</thresh><feature>0</feature><depth>1</depth><gini>0</gini><dominant_class>None</dominant_class><acc_dominant_class>None</acc_dominant_class></node><node><thresh>0</thresh><feature>0</feature><depth>1</depth><gini>0</gini><dominant_class>None</dominant_class><acc_dominant_class>None</acc_dominant_class></node></node>\n"
          ]
        }
      ],
      "source": [
        "print(xml_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "g3i5R8VvO2Y7"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Node_CART:\n",
        "    def __init__(self, num_classes=4, ref_CART=None, current_depth=0):\n",
        "        self.ref_CART = ref_CART\n",
        "        self.threshold_value = 0\n",
        "        self.feature_num = 0\n",
        "        self.node_right = None\n",
        "        self.node_left = None\n",
        "        self.data_torch_partition = None\n",
        "        self.gini = 0\n",
        "        self.dominant_class = None\n",
        "        self.accuracy_dominant_class = None\n",
        "        self.num_classes = num_classes\n",
        "        self.current_depth = current_depth\n",
        "        self.max_depth = None  # Optional: set externally if needed\n",
        "\n",
        "    def to_xml(self, current_str=\"\"):\n",
        "        str_node = \"<node><thresh>\" + str(self.threshold_value) + \"</thresh>\" + \"<feature>\" + str(self.feature_num) + \"</feature><depth>\" + str(self.current_depth)+ \"</depth>\"\n",
        "        str_node += \"<gini>\" + str(self.gini) + \"</gini>\"\n",
        "        if self.node_right is not None:\n",
        "            str_node += self.node_right.to_xml(current_str)\n",
        "        if self.node_left is not None:\n",
        "            str_node += self.node_left.to_xml(current_str)\n",
        "        if self.is_leaf():\n",
        "            str_node += \"<dominant_class>\" + str(self.dominant_class) + \"</dominant_class><acc_dominant_class>\"  + str(self.accuracy_dominant_class) + \"</acc_dominant_class>\"\n",
        "        str_node += \"</node>\"\n",
        "        return str_node\n",
        "\n",
        "    def is_leaf(self):\n",
        "        return (self.node_left is None and self.node_right is None)\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_gini(data_partition_torch, num_classes=2):\n",
        "        if data_partition_torch.numel() == 0:\n",
        "            return 0.0\n",
        "        labels = data_partition_torch[:, -1].long()\n",
        "        # Cuenta cuántos ejemplos hay de cada clase\n",
        "        counts = torch.bincount(labels, minlength=num_classes)\n",
        "        probs = counts.float() / counts.sum()\n",
        "        gini = 1.0 - torch.sum(probs ** 2)\n",
        "        return gini.item()\n",
        "\n",
        "    def create_with_children(self, data_torch, current_depth, min_gini=0.000001):\n",
        "        labels = data_torch[:, -1].long()\n",
        "        counts = torch.bincount(labels, minlength=self.num_classes).float()\n",
        "        self.dominant_class = torch.argmax(counts).item()\n",
        "\n",
        "        # If pure node, make leaf\n",
        "        if (counts > 0).sum() == 1:\n",
        "            print('Pure node, exit')\n",
        "            return self\n",
        "\n",
        "        # If max depth reached\n",
        "        if self.max_depth is not None and current_depth >= self.max_depth:\n",
        "            print(\"Reached Max_depth\")\n",
        "            return self\n",
        "\n",
        "        # Select best split\n",
        "        feature, thresh, gini = self.select_best_feature_and_thresh(data_torch, self.num_classes)\n",
        "        # If no good split, make leaf\n",
        "        if feature is None or gini < min_gini:\n",
        "            print('No good split, exit')\n",
        "            return self\n",
        "\n",
        "        self.feature_num = feature\n",
        "        self.threshold_value = thresh\n",
        "        self.gini = gini\n",
        "\n",
        "        # Partition data\n",
        "        left_mask = data_torch[:, feature] < thresh\n",
        "        right_mask = ~left_mask\n",
        "\n",
        "        left_partition = data_torch[left_mask]\n",
        "        right_partition = data_torch[right_mask]\n",
        "\n",
        "        # Create child nodes\n",
        "        self.node_left = Node_CART(num_classes=self.num_classes, current_depth=current_depth + 1)\n",
        "        self.node_right = Node_CART(num_classes=self.num_classes, current_depth=current_depth + 1)\n",
        "        self.node_left.max_depth = self.max_depth\n",
        "        self.node_right.max_depth = self.max_depth\n",
        "\n",
        "        self.node_left.create_with_children(left_partition, current_depth + 1, min_gini)\n",
        "        self.node_right.create_with_children(right_partition, current_depth + 1, min_gini)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def select_best_feature_and_thresh(self, data_torch, num_classes=2):\n",
        "        n_samples, n_features = data_torch.shape[0], data_torch.shape[1] - 1\n",
        "        best_gini = float('inf')\n",
        "        best_feature = None\n",
        "        best_thresh = None\n",
        "\n",
        "        for feature_idx in range(n_features):\n",
        "            feature_values = data_torch[:, feature_idx]\n",
        "            sorted_vals = torch.sort(feature_values.unique())[0]\n",
        "            # Only try thresholds between unique values\n",
        "            if len(sorted_vals) > 1:\n",
        "                thresholds = (sorted_vals[:-1] + sorted_vals[1:]) / 2\n",
        "            else:\n",
        "                thresholds = sorted_vals  # Only one value, no split possible\n",
        "\n",
        "            for thresh in thresholds:\n",
        "                left_mask = feature_values < thresh\n",
        "                right_mask = ~left_mask\n",
        "\n",
        "                left_partition = data_torch[left_mask]\n",
        "                right_partition = data_torch[right_mask]\n",
        "\n",
        "                gini_left = self.calculate_gini(left_partition, num_classes)\n",
        "                gini_right = self.calculate_gini(right_partition, num_classes)\n",
        "\n",
        "                weighted_gini = (left_partition.size(0) * gini_left +\n",
        "                                 right_partition.size(0) * gini_right) / n_samples\n",
        "\n",
        "                if weighted_gini < best_gini:\n",
        "                    best_gini = weighted_gini\n",
        "                    best_feature = feature_idx\n",
        "                    best_thresh = thresh.item()\n",
        "\n",
        "        return best_feature, best_thresh, best_gini\n",
        "\n",
        "    def evaluate_node(self, input_torch):\n",
        "        feature_val_input = input_torch[self.feature_num]\n",
        "        if self.is_leaf():\n",
        "            return self.dominant_class\n",
        "        else:\n",
        "            if feature_val_input < self.threshold_value:\n",
        "                return self.node_left.evaluate_node(input_torch)\n",
        "            else:\n",
        "                return self.node_right.evaluate_node(input_torch)\n",
        "\n",
        "def test_CART(root_node, D):\n",
        "    \"\"\"\n",
        "    Evalúa un árbol CART previamente entrenado (root_node) sobre un conjunto de datos D (tensor).\n",
        "    Calcula y retorna la tasa de aciertos (accuracy), definida como:\n",
        "        accuracy = c / n\n",
        "    donde:\n",
        "        c = número de estimaciones correctas (predicción == etiqueta real)\n",
        "        n = número total de muestras\n",
        "\n",
        "    Parámetros:\n",
        "        root_node (Node_CART): nodo raíz del árbol entrenado.\n",
        "        D (torch.Tensor): conjunto de datos, última columna es la etiqueta.\n",
        "\n",
        "    Retorna:\n",
        "        float: tasa de aciertos (accuracy).\n",
        "    \"\"\"\n",
        "    # Contador de aciertos\n",
        "    correct = 0\n",
        "    n = D.shape[0]\n",
        "\n",
        "    # Para cada muestra en D\n",
        "    for i in range(n):\n",
        "        sample = D[i, :-1]  # Todas las columnas menos la última (features)\n",
        "        true_label = D[i, -1].item()  # Última columna (etiqueta real)\n",
        "        pred_label = root_node.evaluate_node(sample)  # Predicción del árbol\n",
        "\n",
        "        if pred_label == true_label:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / n\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "kdD4lGFZO2ZC",
        "outputId": "e7aef6ae-0484-4ba8-a2f3-0d6d5cd30de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'left_child' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-562433863.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gini_left: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgini_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gini_right: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgini_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gini_total: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgini_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgini_total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgini_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gini_total \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgini_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'left_child' is not defined"
          ]
        }
      ],
      "source": [
        "def calculate_gini(node_left, node_right):\n",
        "  size_left = node_left.data_torch_partition.shape[0]\n",
        "  size_right = node_right.data_torch_partition.shape[0]\n",
        "  size_total = size_left + size_right\n",
        "  gini_left = 1 - (((node_left.data_torch_partition[:, 3] == 0).sum().item() / size_left)**2 + ((node_left.data_torch_partition[:, 3] == 1).sum().item()/size_left)**2)\n",
        "  gini_right = 1 - (((node_right.data_torch_partition[:, 3] == 0).sum().item() / size_right)**2 + ((node_right.data_torch_partition[:, 3] == 1).sum().item()/size_right)**2)\n",
        "  gini_total = (size_left / size_total * gini_left) + (size_right / size_total * gini_right)\n",
        "  print(\"gini_left: \", gini_left, \"gini_right: \", gini_right, \"gini_total: \", gini_total)\n",
        "  return gini_total\n",
        "gini_total = calculate_gini(left_child, right_child)\n",
        "print(\"gini_total \", gini_total)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unit Tests función: calculate_gini"
      ],
      "metadata": {
        "id": "k57BcAddAJqY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "SSQHnsCCO2ZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d942a6-d60c-46df-da80-c0d78beda79c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1 - Gini homogéneo: 0.0\n",
            "Test 2 - Gini balanceado: 0.5\n"
          ]
        }
      ],
      "source": [
        "# Prueba unitaria 1: Gini para un solo grupo homogéneo (impureza debe ser 0)\n",
        "def test_gini_homogeneous():\n",
        "    node = Node_CART(num_classes=2)\n",
        "    # Todos los elementos son de la clase 0\n",
        "    data = torch.tensor([[1, 2, 0], [2, 3, 0], [3, 4, 0]], dtype=torch.float32)\n",
        "    gini = node.calculate_gini(data, num_classes=2)\n",
        "    print('Test 1 - Gini homogéneo:', gini)\n",
        "    assert abs(gini - 0.0) < 1e-6, f\"Esperado 0.0, obtenido {gini}\"\n",
        "\n",
        "# Prueba unitaria 2: Gini para dos clases balanceadas (impureza máxima)\n",
        "def test_gini_balanced():\n",
        "    node = Node_CART(num_classes=2)\n",
        "    # Mitad clase 0, mitad clase 1\n",
        "    data = torch.tensor([[1, 2, 0], [2, 3, 1], [3, 4, 0], [4, 5, 1]], dtype=torch.float32)\n",
        "    gini = node.calculate_gini(data, num_classes=2)\n",
        "    print('Test 2 - Gini balanceado:', gini)\n",
        "    assert abs(gini - 0.5) < 1e-6, f\"Esperado 0.5, obtenido {gini}\"\n",
        "\n",
        "# Ejecutar pruebas\n",
        "test_gini_homogeneous()\n",
        "test_gini_balanced()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit Tests función: select_best_feature_and_thresh"
      ],
      "metadata": {
        "id": "69xp2326yC7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def test_select_best_feature_and_thresh():\n",
        "    # El feature 0 separa perfectamente las clases con threshold 2\n",
        "    # [feature0, feature1, clase]\n",
        "    data = torch.tensor([\n",
        "        [1.0, 10.0, 0],\n",
        "        [2.0, 20.0, 0],\n",
        "        [3.0, 30.0, 1],\n",
        "        [4.0, 40.0, 1]\n",
        "    ])\n",
        "\n",
        "    node = Node_CART(num_classes=2)\n",
        "    best_feature, best_thresh, best_gini = node.select_best_feature_and_thresh(data, num_classes=2)\n",
        "\n",
        "    print(\"Mejor feature:\", best_feature)\n",
        "    print(\"Mejor threshold:\", best_thresh)\n",
        "    print(\"Mejor gini:\", best_gini)\n",
        "\n",
        "\n",
        "    # Esperamos que el mejor feature sea 0 y el mejor threshold sea 2.0 entre 3.0 (ambos separan perfectamente)\n",
        "    assert best_feature == 0, \"El mejor feature debería ser la columna 0\"\n",
        "    assert best_thresh < 3, \"El mejor threshold debería ser entre 2.0 y 3.0\"\n",
        "    assert best_gini == 0.0, \"El gini debería ser 0 para una separación perfecta\"\n",
        "\n",
        "\n",
        "\n",
        "def test_select_best_feature_and_thresh_feature2():\n",
        "    # Dataset: solo la columna 2 permite separación perfecta con threshold 12.5\n",
        "    # [feature0, feature1, feature2, clase]\n",
        "    data = torch.tensor([\n",
        "        [0.0, 1.0, 10.0, 1],\n",
        "        [0.0, 1.0, 11.0, 1],\n",
        "        [0.0, 1.0, 12.0, 1],\n",
        "        [0.0, 1.0, 13.0, 0],\n",
        "        [0.0, 1.0, 14.0, 0],\n",
        "        [0.0, 1.0, 15.0, 0],\n",
        "        [0.0, 1.0, 16.0, 0],\n",
        "        [0.0, 1.0, 17.0, 0],\n",
        "    ])\n",
        "\n",
        "    node = Node_CART(num_classes=2)\n",
        "    best_feature, best_thresh, best_gini = node.select_best_feature_and_thresh(data, num_classes=2)\n",
        "\n",
        "    print(\"Mejor feature:\", best_feature)\n",
        "    print(\"Mejor threshold:\", best_thresh)\n",
        "    print(\"Mejor gini:\", best_gini)\n",
        "\n",
        "    # Esperamos que el mejor feature sea 2 (columna 2) y threshold  13.0\n",
        "    assert best_feature == 2, \"El mejor feature debería ser la columna 2\"\n",
        "\n",
        "    assert best_thresh < 13.0 , \"El mejor threshold debería ser entre 12 y 13\"\n",
        "    assert best_gini == 0.0, \"El gini debería ser 0 para una separación perfecta\"\n",
        "\n",
        "print(\" *** Unit test de select_best_feature_and_thresh \")\n",
        "print(\"Test #1 de la función select_best_feature_and_thresh. El feature 0 separa perfectamente las clases con threshold 2.5\")\n",
        "test_select_best_feature_and_thresh()\n",
        "\n",
        "print(\"_____________________________________________________\")\n",
        "\n",
        "print(\"Test #1 de la función select_best_feature_and_thresh. El feature 0 separa perfectamente las clases con threshold 2.5\")\n",
        "test_select_best_feature_and_thresh_feature2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl9Z-gNkyGsP",
        "outputId": "b0ad57de-dec8-4003-bfde-c4dc319138d1"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " *** Unit test de select_best_feature_and_thresh \n",
            "Test #1 de la función select_best_feature_and_thresh. El feature 0 separa perfectamente las clases con threshold 2.5\n",
            "Mejor feature: 0\n",
            "Mejor threshold: 2.5\n",
            "Mejor gini: 0.0\n",
            "_____________________________________________________\n",
            "Test #1 de la función select_best_feature_and_thresh. El feature 0 separa perfectamente las clases con threshold 2.5\n",
            "Mejor feature: 2\n",
            "Mejor threshold: 12.5\n",
            "Mejor gini: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unit Test función: test_card"
      ],
      "metadata": {
        "id": "JTa7pzb7A_Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_CART_trivial():\n",
        "    # Árbol hoja que siempre predice 1\n",
        "    class DummyNode:\n",
        "        def evaluate_node(self, x):\n",
        "            return 1\n",
        "\n",
        "    D = torch.tensor([\n",
        "        [1.0, 2.0, 1],\n",
        "        [2.0, 3.0, 0],\n",
        "        [3.0, 4.0, 1],\n",
        "        [4.0, 5.0, 1],\n",
        "    ])\n",
        "    dummy_root = DummyNode()\n",
        "    acc = test_CART(dummy_root, D)\n",
        "    print(\"Accuracy árbol trivial:\", acc)\n",
        "    assert acc == 0.75, \"El accuracy debería ser 0.75\"\n",
        "\n",
        "def test_CART_simple_CART():\n",
        "    # Dataset perfectamente separable por feature 0 con threshold 2.0\n",
        "    data = torch.tensor([\n",
        "        [1.0, 10.0, 0],\n",
        "        [2.0, 20.0, 0],\n",
        "        [3.0, 30.0, 1],\n",
        "        [4.0, 40.0, 1]\n",
        "    ])\n",
        "\n",
        "    node = Node_CART(num_classes=2)\n",
        "    node.create_with_children(data, current_depth=0, min_gini=0.0)\n",
        "    acc = test_CART(node, data)  # accuracy\n",
        "    print(\"Accuracy árbol perfectamente valanceado:\", acc)\n",
        "    assert acc == 1.0, \"El accuracy debería ser 1\"\n",
        "\n",
        "def test_CART_DEPTH_2():\n",
        "  data = torch.tensor([\n",
        "      [1.0, 0.0, 1.0, 0],\n",
        "      [1.0, 0.0, 2.0, 0],\n",
        "      [1.0, 0.0, 3.0, 1],\n",
        "      [1.0, 0.0, 4.0, 0],\n",
        "      [1.0, 0.0, 5.0, 0],\n",
        "      [1.0, 0.0, 6.0, 0],\n",
        "  ])\n",
        "\n",
        "  node = Node_CART(num_classes=2)\n",
        "  node.create_with_children(data, current_depth=0)\n",
        "  acc = test_CART(node, data)  # accuracy\n",
        "  print(\"Accuracy árbol usando un min gini mayor a 0\", acc)\n",
        "  assert acc < 1.0 and acc >0, \"El accuracy debería ser menor que uno y mayor a 0, usando un min gini mayor a 0\"\n",
        "\n",
        "def test_CART_DEPTH_2_Gin0():\n",
        "  data = torch.tensor([\n",
        "      [1.0, 0.0, 1.0, 0],\n",
        "      [1.0, 0.0, 2.0, 0],\n",
        "      [1.0, 0.0, 3.0, 1],\n",
        "      [1.0, 0.0, 4.0, 0],\n",
        "      [1.0, 0.0, 5.0, 0],\n",
        "      [1.0, 0.0, 6.0, 0],\n",
        "  ])\n",
        "\n",
        "  node = Node_CART(num_classes=2)\n",
        "  node.create_with_children(data, current_depth=0, min_gini=0)\n",
        "  acc = test_CART(node, data)  # accuracy\n",
        "  print(\"Accuracy árbol usando un min gini 0\", acc)\n",
        "  assert acc == 1 , \"El accuracy debería ser igual a 1\"\n",
        "\n",
        "test_CART_simple_CART()\n",
        "test_CART_DEPTH_2()\n",
        "test_CART_DEPTH_2_Gin0()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v99gdhrBONy",
        "outputId": "439eee22-ce9c-41ae-961e-98f6566bda55"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select the best split  2\n",
            "feature  0\n",
            "thresh  2.5\n",
            "gini  0.0\n",
            "Pure node, exit\n",
            "Pure node, exit\n",
            "Accuracy árbol perfectamente valanceado: 1.0\n",
            "Select the best split  2\n",
            "feature  2\n",
            "thresh  3.5\n",
            "gini  0.2222222089767456\n",
            "Select the best split  2\n",
            "feature  2\n",
            "thresh  2.5\n",
            "gini  0.0\n",
            "No good split, exit\n",
            "Pure node, exit\n",
            "Accuracy árbol usando un min gini mayor a 0 0.8333333333333334\n",
            "Select the best split  2\n",
            "feature  2\n",
            "thresh  3.5\n",
            "gini  0.2222222089767456\n",
            "Select the best split  2\n",
            "feature  2\n",
            "thresh  2.5\n",
            "gini  0.0\n",
            "Pure node, exit\n",
            "Pure node, exit\n",
            "Pure node, exit\n",
            "Accuracy árbol usando un min gini 0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_example = torch.tensor([\n",
        "    [1.0, 0.0, 1.0, 0],\n",
        "    [1.0, 0.0, 2.0, 0],\n",
        "    [1.0, 0.0, 3.0, 1],\n",
        "    [1.0, 0.0, 4.0, 0],\n",
        "    [1.0, 0.0, 5.0, 0],\n",
        "    [1.0, 0.0, 6.0, 0],\n",
        "])\n",
        "newNode = Node_CART(num_classes=2)\n",
        "newNode.create_with_children(dataset_example, 0)\n",
        "xml_string =newNode.to_xml()\n",
        "\n",
        "#print(xml_string)\n",
        "#file = open(\"example1.xml\", \"a\")\n",
        "#file.write(xml_string)\n",
        "#file.close()\n",
        "print(xml_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoTypq9kBLrk",
        "outputId": "975520ba-8e15-40ba-9e6e-4119930110fd"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select the best split  2\n",
            "feature  2\n",
            "thresh  3.5\n",
            "gini  0.2222222089767456\n",
            "Select the best split  2\n",
            "feature  2\n",
            "thresh  2.5\n",
            "gini  0.0\n",
            "No good split, exit\n",
            "Pure node, exit\n",
            "<node><thresh>3.5</thresh><feature>2</feature><depth>0</depth><gini>0.2222222089767456</gini><node><thresh>0</thresh><feature>0</feature><depth>1</depth><gini>0</gini><dominant_class>0</dominant_class><acc_dominant_class>None</acc_dominant_class></node><node><thresh>0</thresh><feature>0</feature><depth>1</depth><gini>0</gini><dominant_class>0</dominant_class><acc_dominant_class>None</acc_dominant_class></node></node>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}