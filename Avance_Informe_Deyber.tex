\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[margin=2.5cm]{geometry}

\title{\textbf{Trabajo Práctico 1: Árboles de Decisión para Ciberseguridad}\\
        \large{Implementación de CART desde cero para detección de ataques backdoor}}
\author{[Tu Nombre Completo] \\
         [Tu Carné] \\
         Análisis de Datos para Ciberseguridad \\
         Instituto Tecnológico de Costa Rica}
\date{Agosto 2025}

\begin{document}

\maketitle

\begin{abstract}
En este trabajo práctico se implementa un algoritmo de Classification and Regression Tree (CART) completamente desde cero para la detección de ataques backdoor en redes de computadoras. Utilizando el dataset KDD99, se desarrolló una solución que incluye análisis descriptivo con PyTorch, implementación matricial del coeficiente de Gini, y evaluación exhaustiva mediante validación cruzada. Los resultados muestran un accuracy promedio de 0.9950 ± 0.0025 y un F1-score de 0.9945, demostrando la efectividad del enfoque implementado.
\end{abstract}

\section{Introducción}

La detección de intrusos en redes de computadoras es un problema crítico en ciberseguridad que requiere técnicas de machine learning robustas y interpretables. Los árboles de decisión, específicamente el algoritmo CART (Classification and Regression Trees), ofrecen una solución efectiva debido a su capacidad de generar reglas comprensibles y su eficiencia computacional.

El dataset KDD Cup 1999 \cite{kdd99} es uno de los benchmarks más utilizados para evaluar sistemas de detección de intrusos. Contiene registros de conexiones de red etiquetadas como normales o como diversos tipos de ataques. Para este trabajo, nos enfocamos específicamente en la detección de ataques tipo \textit{backdoor}, que representan intentos de acceso no autorizado mediante puertas traseras instaladas previamente.

\subsection{Objetivos}

Los objetivos específicos de este trabajo son:

\begin{enumerate}
    \item Realizar un análisis descriptivo exhaustivo del dataset utilizando momentos estadísticos calculados con PyTorch
    \item Implementar completamente desde cero un algoritmo CART binario para clasificación
    \item Evaluar el rendimiento del modelo mediante múltiples métricas y validación cruzada
    \item Analizar la estructura del mejor árbol obtenido y su relación con las características más discriminativas
\end{enumerate}

\section{Metodología}

\subsection{Descripción del Dataset}

El dataset KDD99 utilizado contiene 41 características que describen conexiones de red, categorizadas en:

\begin{itemize}
    \item \textbf{Características básicas}: Información general como duración, protocolo, servicio
    \item \textbf{Características de contenido}: Análisis del contenido para detectar accesos no autorizados
    \item \textbf{Características de tráfico temporal}: Estadísticas en ventanas de tiempo
    \item \textbf{Características de tráfico por host}: Estadísticas hacia el mismo host
\end{itemize}

Para este estudio se filtraron únicamente las conexiones etiquetadas como \texttt{normal.} y \texttt{back.}, resultando en un dataset de clasificación binaria con 99,481 instancias (97,278 normales y 2,203 backdoor).

\subsection{Análisis Descriptivo}

\subsubsection{Momentos Estadísticos con PyTorch}

Se implementó el cálculo de los cuatro momentos estadísticos principales utilizando operaciones matriciales de PyTorch:

\begin{align}
\text{Media:} \quad \mu &= \frac{1}{n} \sum_{i=1}^{n} x_i \\
\text{Desviación estándar:} \quad \sigma &= \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2} \\
\text{Asimetría:} \quad \text{skew} &= \frac{1}{n} \sum_{i=1}^{n} \left(\frac{x_i - \mu}{\sigma}\right)^3 \\
\text{Kurtosis:} \quad \text{kurt} &= \frac{1}{n} \sum_{i=1}^{n} \left(\frac{x_i - \mu}{\sigma}\right)^4
\end{align}

\subsubsection{Distancia Jensen-Shannon}

Para cuantificar las diferencias entre las distribuciones de características en ambas clases, se calculó la distancia Jensen-Shannon:

\begin{equation}
JS(P,Q) = \sqrt{\frac{1}{2}[D_{KL}(P||M) + D_{KL}(Q||M)]}
\end{equation}

donde $M = \frac{1}{2}(P + Q)$ y $D_{KL}$ es la divergencia de Kullback-Leibler.

La característica más discriminativa encontrada fue \texttt{src_bytes} con una distancia JS de 0.8532.

\subsection{Implementación CART}

\subsubsection{Coeficiente de Gini}

Se implementó el cálculo matricial del coeficiente de Gini sin uso de bucles:

\begin{equation}
\text{Gini}(\tau_d) = 1 - \sum_{k=1}^{K} a_k^2
\end{equation}

donde $a_k$ es la proporción de la clase $k$ en el nodo.

\subsubsection{Selección de Características y Umbrales}

El algoritmo evalúa exhaustivamente todas las características y umbrales candidatos utilizando indexación lógica:

\begin{equation}
\text{Gini}_{weighted}(\tau_d, d) = \frac{n_i}{n}\text{Gini}(D_i) + \frac{n_d}{n}\text{Gini}(D_d)
\end{equation}

\subsubsection{Función de Evaluación}

La función \texttt{test\_CART} calcula el accuracy como:

\begin{equation}
\text{Accuracy} = \frac{c}{n}
\end{equation}

donde $c$ es el número de predicciones correctas y $n$ el total de muestras.

\subsection{Pruebas Unitarias}

Se implementaron 6 pruebas unitarias que verifican:
\begin{itemize}
    \item Cálculo correcto de Gini para datasets balanceados y puros
    \item Búsqueda válida de características y umbrales
    \item Manejo de casos límite (datasets indivisibles)
    \item Formato correcto de predicciones
\end{itemize}

\section{Resultados}

\subsection{Evaluación Básica}

Se evaluó el modelo con profundidades máximas de 3 y 4 niveles, manteniendo un mínimo de 2 observaciones por hoja. Los resultados muestran excelente rendimiento en ambas configuraciones.

\subsection{Evaluación con 10 Corridas}

Se realizaron 10 corridas independientes con partición estratificada 70/30. La Tabla \ref{tab:evaluacion} muestra las estadísticas resumidas.

% INSERTAR TABLA DE EVALUACIÓN
\begin{table}[H]
\centering
\caption{Resumen estadístico de 10 corridas (Promedio ± Desviación Estándar)}
\label{tab:evaluacion}
\begin{tabular}{lc}
\toprule
\textbf{Métrica} & \textbf{Valor} \\
\midrule
Accuracy & 0.9950 ± 0.0025 \\
F1-Score (macro) & 0.9945 ± 0.0039 \\
Tiempo entrenamiento (s) & 0.1250 ± 0.5406 \\
Tiempo evaluación (s) & 0.0013 ± 0.0000 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Análisis del Mejor Árbol}

El modelo con mejor rendimiento utilizó 6 características principales relacionadas con el tráfico de red y servicios. Este árbol demostró capacidad de generalización excelente manteniendo interpretabilidad.

\subsubsection{Características Más Importantes}

Basado en el análisis Jensen-Shannon, las características más discriminativas incluyen:
\begin{enumerate}
    \item \texttt{hot} (JS: 0.8218)
    \item \texttt{src_bytes} (JS: 0.8090)
    \item \texttt{dst_host_srv_rerror_rate} (JS: 0.6027)
\end{enumerate}

\section{Discusión}

\subsection{Rendimiento del Modelo}

Los resultados obtenidos demuestran que la implementación CART desde cero es altamente efectiva para la detección de ataques backdoor. El accuracy promedio de 0.9950 supera ampliamente el umbral de efectividad para aplicaciones de ciberseguridad.

\subsection{Eficiencia Computacional}

El tiempo promedio de entrenamiento de 0.1250 segundos demuestra la eficiencia de la implementación matricial utilizada. La indexación lógica evitó bucles innecesarios, optimizando significativamente el rendimiento.

\subsection{Interpretabilidad}

Una ventaja clave de los árboles de decisión es su interpretabilidad. El análisis del mejor árbol revela que las decisiones se basan principalmente en características relacionadas con el volumen de datos transferidos y patrones de servicios, lo cual es consistente con el comportamiento esperado de ataques backdoor.

\section{Conclusiones}

Este trabajo práctico logró implementar exitosamente un algoritmo CART completo desde cero, cumpliendo todos los objetivos planteados:

\begin{enumerate}
    \item Se realizó un análisis descriptivo exhaustivo utilizando PyTorch para cálculos matriciales
    \item Se implementó CART con todas las funciones requeridas y pruebas unitarias
    \item Se evaluó robustamente el modelo mediante múltiples métricas
    \item Se analizó la estructura del mejor árbol y su relación con características discriminativas
\end{enumerate}

\subsection{Contribuciones Técnicas}

\begin{itemize}
    \item Implementación matricial eficiente del coeficiente de Gini
    \item Búsqueda exhaustiva optimizada mediante indexación lógica  
    \item Análisis comparativo usando distancia Jensen-Shannon
    \item Framework de evaluación robusto con validación cruzada
\end{itemize}

\subsection{Trabajo Futuro}

Las líneas de investigación futuras podrían incluir:
\begin{itemize}
    \item Extensión a clasificación multiclase para otros tipos de ataques
    \item Implementación de técnicas de ensemble (Random Forest)
    \item Optimización adicional para datasets de mayor escala
    \item Comparación con algoritmos de deep learning
\end{itemize}

\section{Referencias}

\begin{thebibliography}{9}
\bibitem{kdd99}
KDD Cup 1999 Dataset. University of California, Irvine. 
\texttt{https://kdd.ics.uci.edu/databases/kddcup99/}

\bibitem{breiman}
Breiman, L., Friedman, J., Stone, C. J., \& Olshen, R. A. (1984). 
\textit{Classification and regression trees}. CRC press.

\bibitem{pytorch}
Paszke, A., et al. (2019). PyTorch: An imperative style, high-performance deep learning library. 
\textit{Advances in neural information processing systems}, 32.
\end{thebibliography}

\appendix

\section{Código Fuente}
El código fuente completo se encuentra disponible en el notebook Jupyter adjunto, incluyendo todas las implementaciones y pruebas unitarias realizadas.

\section{Archivos Adicionales}
\begin{itemize}
    \item \texttt{mejor\_arbol.xml}: Estructura del árbol con mejor rendimiento
    \item \texttt{momentos\_estadisticos.csv}: Análisis descriptivo completo
    \item \texttt{ranking\_jensen\_shannon.csv}: Características ordenadas por discriminación
\end{itemize}

\end{document}
